<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>3D Hair Filter</title>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils"></script>
  <script src="https://cdn.jsdelivr.net/npm/three@0.152.2/build/three.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/three@0.152.2/examples/js/loaders/GLTFLoader.js"></script>
  <style>
    body {
      margin: 0;
      overflow: hidden;
    }
    video {
      display: none;
    }
    canvas {
      display: block;
    }
  </style>
</head>
<body>
  <video id="video" autoplay muted playsinline></video>
  <canvas id="threeCanvas"></canvas>

  <script>
    // Video and Canvas Elements
    const videoElement = document.getElementById('video');
    const canvasElement = document.getElementById('threeCanvas');

    // Three.js Scene, Camera, and Renderer
    const scene = new THREE.Scene();
    const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
    const renderer = new THREE.WebGLRenderer({ canvas: canvasElement, alpha: true });

    renderer.setSize(window.innerWidth, window.innerHeight);
    camera.position.set(0, 0, 2);

    const light = new THREE.AmbientLight(0xffffff, 1); // Ambient light
    scene.add(light);

    // Load 3D Hair Model
    const loader = new THREE.GLTFLoader();
    let hairModel;

    loader.load('path/to/your/hair_model.glb', function (gltf) {
      hairModel = gltf.scene;
      hairModel.scale.set(0.1, 0.1, 0.1); // Adjust size to fit the head
      hairModel.visible = false; // Hide until landmarks are detected
      scene.add(hairModel);
    });

    // Mediapipe Face Mesh Setup
    const faceMesh = new FaceMesh({
      locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`,
    });

    faceMesh.setOptions({
      maxNumFaces: 1,
      minDetectionConfidence: 0.5,
      minTrackingConfidence: 0.5,
    });

    faceMesh.onResults(onResults);

    const cameraUtils = new Camera(videoElement, {
      onFrame: async () => {
        await faceMesh.send({ image: videoElement });
      },
      width: 1280,
      height: 720,
    });

    cameraUtils.start();

    // Face Mesh Results Handler
    function onResults(results) {
      if (!results.multiFaceLandmarks || !hairModel) return;

      const landmarks = results.multiFaceLandmarks[0];
      const forehead = landmarks[10]; // Example: Forehead landmark
      const noseBridge = landmarks[6]; // Example: Nose bridge for rotation reference

      // Position the hair model
      hairModel.position.set(
        (forehead.x - 0.5) * 2, // Map x to 3D space
        -(forehead.y - 0.5) * 2, // Map y to 3D space
        -2 // Adjust depth
      );

      // Calculate rotation
      const dx = noseBridge.x - forehead.x;
      const dy = noseBridge.y - forehead.y;
      const rotation = Math.atan2(dy, dx);

      hairModel.rotation.set(0, 0, rotation);
      hairModel.visible = true; // Make the model visible when landmarks are detected
    }

    // Animation Loop
    function animate() {
      requestAnimationFrame(animate);
      renderer.render(scene, camera);
    }
    animate();
  </script>
</body>
</html>
