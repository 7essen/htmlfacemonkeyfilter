<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Face Filter Demo</title>
    <script type="importmap">
    {
        "imports": {
            "three": "https://unpkg.com/three@0.160.0/build/three.module.js",
            "three/addons/": "https://unpkg.com/three@0.160.0/examples/jsm/",
            "@mediapipe/face_mesh": "https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"
        }
    }
    </script>
    <style>
        body { margin: 0; }
        canvas { display: block; }
        #video {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            object-fit: cover;
        }
        #canvas3d {
            position: fixed;
            top: 0;
            left: 0;
            pointer-events: none;
        }
    </style>
</head>
<body>
    <video id="video" playsinline></video>
    <canvas id="canvas3d"></canvas>

    <script type="module">
        import * as THREE from 'three';
        import { GLTFLoader } from 'three/addons/loaders/GLTFLoader.js';
        import { FaceMesh } from '@mediapipe/face_mesh';

        // Set up Three.js scene
        const scene = new THREE.Scene();
        const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
        const renderer = new THREE.WebGLRenderer({
            canvas: document.getElementById('canvas3d'),
            alpha: true
        });
        renderer.setSize(window.innerWidth, window.innerHeight);

        // Add lighting
        const light = new THREE.DirectionalLight(0xffffff, 1);
        light.position.set(0, 1, 1);
        scene.add(light);
        scene.add(new THREE.AmbientLight(0xffffff, 0.5));

        // Load 3D model
        const loader = new GLTFLoader();
        let model;
        loader.load('aespa_short_hair_with_bones.glb', (gltf) => {
            model = gltf.scene;
            scene.add(model);
            model.scale.set(0.1, 0.1, 0.1);
        });

        // Set up face tracking
        const faceMesh = new FaceMesh({
            locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`
        });

        faceMesh.setOptions({
            maxNumFaces: 1,
            refineLandmarks: true,
            minDetectionConfidence: 0.5,
            minTrackingConfidence: 0.5
        });

        // Handle webcam
        const video = document.getElementById('video');
        async function setupCamera() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ video: true });
                video.srcObject = stream;
                return new Promise((resolve) => {
                    video.onloadedmetadata = () => {
                        video.play();
                        resolve(video);
                    };
                });
            } catch (error) {
                console.error('Error accessing the camera:', error);
                alert('Failed to access the camera. Please ensure you have given permission and are using a supported browser.');
            }
        }

        // Process results
        faceMesh.onResults((results) => {
            if (results.multiFaceLandmarks && results.multiFaceLandmarks.length > 0) {
                const landmarks = results.multiFaceLandmarks[0];
                
                if (model) {
                    // Position the model based on nose position (landmark 1)
                    const nose = landmarks[1];
                    model.position.set(
                        (nose.x - 0.5) * 2,
                        -(nose.y - 0.5) * 2,
                        -nose.z
                    );

                    // Update model rotation based on face orientation
                    const forehead = landmarks[10];
                    const chin = landmarks[152];
                    const rotation = Math.atan2(forehead.y - chin.y, forehead.x - chin.x);
                    model.rotation.z = rotation;
                }
            }
        });

        // Start face detection
        const startDetection = async () => {
            try {
                await setupCamera();
                await faceMesh.initialize();
                
                const tick = () => {
                    faceMesh.send({ image: video });
                    renderer.render(scene, camera);
                    requestAnimationFrame(tick);
                };
                
                tick();
            } catch (error) {
                console.error('Error starting detection:', error);
                alert('An error occurred while starting the face detection. Please refresh the page and try again.');
            }
        };

        startDetection();

        // Handle window resize
        window.addEventListener('resize', () => {
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight);
        });
    </script>
</body>
</html>
